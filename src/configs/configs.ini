# rparams - params grid
# gparams - params grid for gridsearch
# n_folds - number of folds for gridsearch >=3 and <=10
# targets and features - array of columns or range(0,100)

[DEFAULT]
n_folds = 3
epochs = 100000
n_iter = 100
class_weight = False
ep = 5

[REGRESSION_HIV]
rparams = {
    "batch_size": 32, 
    "activation": 'sigmoid',    
    "optimizer": 'Nadam', 
    "loss": 'mean_squared_error',    
    "learning_rate": 0.001,    
    "momentum": 0.2,
    "init_mode": 'glorot_normal',
    "metrics": ['accuracy']
    }

gparams = {
    "epochs" : [%(ep)s],
    "batch_size": [1, 8, 32, 128, 512, 2048],
    "activation": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'squared_hinge', 'hinge','binary_crossentropy','poisson','cosine_proximity'],
    "learning_rate": [.01, .001, .0001, .0001, .00001],
    "momentum": [0.0, 0.01, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    "init_mode": ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],
    "metrics": [['accuracy']]
    }

[REGRESSION_MUV]
rparams = {
    "batch_size": 1000, 
    "activation": 'sigmoid', 
    "optimizer": 'Adam', 
    "loss": 'binary_crossentropy',    
    "learning_rate": .000001,     
    "momentum": .9,
    "init_mode": 'uniform',
    "metrics": ['accuracy']
    }
    
gparams = {
    "epochs" : [%(ep)s],
    "batch_size": [1, 8, 32, 128, 512, 2048],
    "activation": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'squared_hinge', 'hinge','binary_crossentropy','poisson','cosine_proximity'],
    "learning_rate": [.01, .001, .0001, .0001, .00001],
    "momentum": [0.0, 0.01, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    "init_mode": ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],
    "metrics": [['accuracy']]
    }

[REGRESSION_TOX21]
rparams = {
    "batch_size": 8, 
    "activation": 'sigmoid', 
    "optimizer": 'Adam', 
    "loss": 'mean_squared_error',    
    "neurons": 32, 
    "learning_rate": .001,     
    "momentum": 0.9,
    "init_mode": 'lecun_uniform',
    "metrics": ['accuracy']
    }

gparams = {
    "epochs" : [%(ep)s],
    "batch_size": [1, 8, 32, 128, 512, 2048],
    "activation": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'squared_hinge', 'hinge','binary_crossentropy','poisson','cosine_proximity'],
    "learning_rate": [.01, .001, .0001, .0001, .00001],
    "momentum": [0.0, 0.01, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    "init_mode": ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],
    "metrics": [['accuracy']]
    }

[RESIDUAL_HIV]
rparams = {
    "batch_size": 8, 
    "activation_0": 'relu', 
    "activation_1": 'relu', 
    "activation_2": 'relu', 
    "optimizer": 'Adam', 
    "loss": 'binary_crossentropy',    
    # "neurons": 32, 
    "learning_rate": .001, 
    "momentum": .1,
    "init_mode": 'uniform',
    "metrics": ['accuracy'],
    "dropout": 0.1,
    "layers": 3
    }

gparams = {
    "epochs" : [%(ep)s],
    "batch_size": [1, 8, 32, 128, 512, 1024],
    "activation_0": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "activation_1": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "activation_2": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 
            'mean_squared_logarithmic_error', 'squared_hinge', 'hinge','binary_crossentropy','kullback_leibler_divergence','poisson','cosine_proximity'],
    "learning_rate": [.01, .001, .0001, 0.0001, .00001],
    "momentum": [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],
    "init_mode": ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],
    "momentum": [0.0, 0.01, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    "layers": [1,2,3,5,10],
    "metrics": [['accuracy']]
    }

[RESIDUAL_MUV]
rparams = {
    "batch_size": 32, 
    "activation_0": 'softmax', 
    "activation_1": 'softmax', 
    "activation_2": 'softmax',
    "optimizer": 'Adam', 
    "loss": 'mean_squared_error',    
    # "neurons": 32, 
    "learning_rate": .0001,     
    "momentum": .1,
    "init_mode": 'uniform',
    "metrics": ['accuracy'],
    "dropout": 0.1,
    "layers": 2
    }

gparams = {
    "epochs" : [%(ep)s],
    "batch_size": [1, 8, 32, 128, 512, 1024],
    "activation_0": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "activation_1": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "activation_2": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 
            'mean_squared_logarithmic_error', 'squared_hinge', 'hinge','binary_crossentropy','kullback_leibler_divergence','poisson','cosine_proximity'],
    "learning_rate": [.01, .001, .0001, 0.0001, .00001],
    "momentum": [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],
    "init_mode": ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],
    "momentum": [0.0, 0.01, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    "layers": [1,2,3,5,10],
    "metrics": [['accuracy']]
    }

[RESIDUAL_TOX21]
rparams = {
    "batch_size": 64, 
    "activation_0": 'relu', 
    "activation_1": 'relu', 
    "activation_2": 'relu',
    "optimizer": 'Adam', 
    "loss": 'binary_crossentropy',    
    "learning_rate": .001,     
    "momentum": .1,
    "init_mode": 'uniform',
    "metrics": ['accuracy'],
    "dropout": 0.1,
    "layers": 3
    }

gparams = {
    "epochs" : [%(ep)s],
    "batch_size": [1, 8, 32, 128, 512, 1024],
    "activation_0": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "activation_1": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "activation_2": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 
            'mean_squared_logarithmic_error', 'squared_hinge', 'hinge','binary_crossentropy','kullback_leibler_divergence','poisson','cosine_proximity'],
    "learning_rate": [.01, .001, .0001, 0.0001, .00001],
    "momentum": [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],
    "init_mode": ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],
    "momentum": [0.0, 0.01, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    "layers": [1,2,3,5,10],
    "metrics": [['accuracy']]
    }
