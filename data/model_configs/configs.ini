# rparams - params grid
# gparams - params grid for gridsearch
# "metrics": [['accuracy'],['average_precision'],['f1'],['f1_micro'],['f1_macro'],['f1_weighted'],['f1_samples'],['neg_log_loss'],['precision'],['recall'],['roc_auc']]


[DEFAULT]
epochs = 5000

[XGB]
rparams = {
    'learning_rate': 0.1, 
    'n_estimators': 1000, 
    'seed':0, 
    'subsample': 0.8, 
    'colsample_bytree': 0.8
    }
    
gparams = {
    'n_estimators': [100*(2*i) for i in range(0,6)],
    "learning_rate": [10**i for i in range(-7, -1)],
    'subsample': [i/10 for i in range(0,10)], 
    'colsample_bytree': [i/10 for i in range(1,10)],
    'max_depth': [2**i for i in range(1,5)],
    'min_child_weight': [0.01, 0.1, 0.2, 0.4, 0.6, 1, 2, 5]
    }

[SVC]
rparams = {'C':1.0, 'cache_size':200, 'coef0':0.0, 'decision_function_shape':'ovr', 
    'degree':3, 'gamma':'auto', 'kernel':'rbf', 'max_iter':-1}

gparams = {
    'C': [10**i for i in range(-2, 5)],
    'kernel': ['linear'],
    'class_weight': ['balanced', None]
    }

gparams_full = [
    {
    'C':[1],
    'kernel':['rbf'],
    'gamma': [0.1],
    'shrinking' : [True, False],
    'class_weight': ['balanced', None]
    },
    {
    'C': [10**i for i in range(-2, 5)],
    'kernel': ['poly'],
    'degree': [3,5,7,9],
    'gamma': [10**i for i in range(-3, 4)],
    'coef0': [10**i for i in range(-5, 0)],
    'shrinking' : [True, False],
    'class_weight': ['balanced', None]
    },
    {
    'C': [10**i for i in range(-2, 4)],
    'kernel':['sigmoid'],
    'gamma': [10**i for i in range(-3, 4)],
    'coef0': [10**i for i in range(-5, 0)],
    'shrinking' : [True, False],
    'class_weight': ['balanced', None]
    },
    {
    'C':[10**i for i in range(-2, 4)],
    'kernel':['linear'],
    'shrinking' : [True, False],
    'class_weight': ['balanced', None]
    }
    ]

[KNN]
rparams = {'n_neighbors':13, 'weights':'uniform', 'algorithm':'auto', 
    'leaf_size':20, 'p':2, 'metric':'minkowski'}
    
gparams = {
    'n_neighbors': [i for i in range(2,20)],
    'weights': ['uniform', 'distance'],
    'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],
    'leaf_size': [1, 3, 5, 9, 10, 20, 30, 50, 100],
    'p' : [1, 2, 3, 5, 7, 9, 13]
    }

[LOGREG]
rparams = {'solver': 'sag', 'max_iter': 10000, 'class_weight': 'balanced', 'C': 0.001}
# solver: sag, max_iter: 100000000, C: 105
gparams = {
    'C': [10**i for i in range(-2, 8)],
    'max_iter': [10**i for i in range(1, 6)],
    'solver': ['sag'], #'newton-cg', 'lbfgs', 'liblinear'],
    'class_weight':['balanced', None]
    }

[RF]
rparams = {
    'n_jobs' : -1, 
    'verbose' : 2,
    'n_estimators' : 500,
    'min_weight_fraction_leaf' : 0.0001,
    'min_samples_split' :  2,
    'min_samples_leaf' : 3,
    'max_leaf_nodes' : 100,
    'criterion' : 'entropy',
    'class_weight': 'balanced'
    }

    
gparams = {
    'n_estimators' : [100*(2*i) for i in range(0,6)],
    'min_samples_leaf' : [1, 5, 10, 15, 30, 60, 100, 200],
    'min_samples_split' : [2, 3, 5, 10, 15, 30, 60, 100],
    'min_weight_fraction_leaf' : [10**i for i in range(-5, 0)],
    'max_leaf_nodes' : [5, 10, 15, 30, 60, 100, 200, 400, 600],
    'criterion' : ['gini', 'entropy'],
    'class_weight': ['balanced', None]
    }

[IF]
rparams = {
    'n_jobs' : -1, 
    'verbose' : 2
    }

    
gparams = {
    'verbose' : [2],
    'n_estimators' : [100*(2*i) for i in range(0,6)],
    'contamination' : [i/10 for i in range(0,6)], 
    'bootstrap' : ['True', 'False']
    }

[REGRESSION]
rparams = {
    "epochs" : 10000,
    'lr': 0.1,
    'l2': 10**(-8),
    "batch_size": 128,
    'momentum' : 0.4,
    'class_weight': 'balanced'
    }

gparams = {
    "epochs" : [100],
    "batch_size": [1, 2, 4, 8, 32, 64, 128, 256, 512],
    'l2' : [10**i for i in range(-10, 3)],
    'lr': [10**i for i in range(-6, -1)],
    'momentum' : [i/10 for i in range(0,10)], 
    'class_weight': ['balanced', None]
    }

[MLP]
rparams = {
    "batch_size": 8
    }

gparams = {
    "epochs" : [100],
    "batch_size": [8, 32, 64, 128, 256, 512],
    "activation_1": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "activation_2": ['softmax', 'elu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],
    "optimizer": ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],
    "loss": ['binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'squared_hinge', 'hinge','binary_crossentropy','poisson','cosine_proximity'],
    "learning_rate": [10**i for i in range(-6, -1)],
    "momentum": [0.0, 0.01, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    "init_mode": ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],
    "class_weight": ['balanced', None],
    "neurons_1":[10,20,30,50,100,200,500,1000,2000],
    "neurons_2":[10,20,30,50,100,200,500,1000,2000],
    "layers":[1,2,3,4,5,10]
    }

[FCNN]
rparams = {
    "bn": True
     }

gparams = {
	"optimizer": ['Adam'], # ['Adam', 'RMSprop', 'SGD', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam']
 	"epochs": [100],
	'hidden_dim_1': [100, 150, 200, 250],
	'hidden_dim_2': [100, 150, 200, 250],
    'dropout_1': [0.0, 0.2, 0.3, 0.5, 0.7],
	'dropout_2': [0.0, 0.2, 0.3, 0.5, 0.7],
    'input_dropout': [0.0, 0.2, 0.3, 0.5, 0.7],
	"class_weight": ['balanced', None],
	"batch_size": [1, 8, 32, 64, 128, 256],
    'l2': [0.00001, 0.0001, 0.001, 0.1]
	}

[MLP_SKLEARN]
rparams = {
    "batch_size": 8
    }

gparams = {
    "hidden_layer_sizes": [tuple([z]*y) for y in range(1,4) for z in (20, 50, 100, 500, 1000, 1500, 2000)],
    "solver": ['lbfgs'], #'sgd', 'adam'],
    "activation": ['identity', 'logistic', 'tanh', 'relu'],
    "alpha": [10**i for i in range(-7, -1)],
    "batch_size": [1, 2, 3, 8, 32, 64, 128], #256, 512, 1024],
    #"learning_rate_init": [10**i for i in range(-5, -1)],
    #"learning_rate" : ['adaptive'], #'constant', 'invscaling'],
    #"momentum": [i/10 for i in range(0,10)],
    #"early_stopping" : [True],
    "max_iter" : [500]
    }


[RBM]
rparams = {
    "batch_size": 8
    }

gparams = {
    "n_components": [10,20,30,50,100,200,500,1000,2000],
    "learning_rate": [.01, .001, .0001, .0001, .00001, 0.00001],
    "batch_size": [1, 2, 8, 32, 64, 128, 256],
    'n_iter': [10, 20, 100, 200, 300, 500, 2000, 5000]
    }
